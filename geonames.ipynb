{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dv2mI-RekpZ4"
   },
   "source": [
    "# Cопоставление геоназваний с унифицированными именами geonames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "NyiuYXdmkpZ6",
    "tags": [
     "a0ea6cf0-58f4-4b62-808c-26c82dd0478d"
    ]
   },
   "source": [
    "# Задача"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KeDGzg2DkpZ6"
   },
   "source": [
    "- Создать решение для подбора наиболее подходящих названий с geonames.\n",
    "Например Ереван -> Yerevan\n",
    "- На примере РФ и стран наиболее популярных для релокации - Беларусь, Армения,\n",
    "Казахстан, Кыргызстан, Турция, Сербия. Города с населением от 15000 человек (с\n",
    "возможностью масштабирования на сервере заказчика)\n",
    "- Возвращаемые поля *geonameid, name, region, country, cosine similarity*\n",
    "- формат данных на выходе: список словарей, например [{dict_1}, {dict_2}, …. {dict_n}], где словарь - одна запись с указанными полями"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y-4YZfQQkpZ6"
   },
   "source": [
    "# Цель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-LsXM-dMkpZ7"
   },
   "source": [
    "Сопоставление произвольных гео названий с унифицированными именами geonames для внутреннего использования Карьерным центром."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fCFPnHMGkpZ7"
   },
   "source": [
    "# План работы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4cFmiRbZkpZ7"
   },
   "source": [
    "\n",
    "- Подготовить данные к обучению.\n",
    "\n",
    " - Метод векторизации слова CountVectorizer();\n",
    " - Метод использования готовой предобученной модели из SentenceTransformers;\n",
    " - Метод использования своей предобученной модели из tansformers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AEuxAKjZkpZ7"
   },
   "source": [
    "# Описание данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0BR2ffuVkpZ7"
   },
   "source": [
    "Используемые таблицы с geonames:\n",
    "- admin1CodesASCII\n",
    "- alternateNamesV2\n",
    "- cities15000\n",
    "- countryInfo\n",
    "- при необходимости любые другие открытые данные\n",
    "- таблицы geonames можно скачать здесь http://download.geonames.org/export/dump/\n",
    "- Тестовый датасет: https://disk.yandex.ru/d/wC296Rj3Yso2AQ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wcU3iu9EkpZ7"
   },
   "source": [
    "**Импортируем необходимые библиотеки (pandas, numpy и другие).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "rzKBvNOxkpZ8"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from count_vec_mod import CountVec\n",
    "from semantic_mod import SemSearch\n",
    "from generation_semantic_mod import GenSearch\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from tqdm import notebook \n",
    "\n",
    "# NLP\n",
    "import torch\n",
    "import transformers\n",
    "import nltk\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymystem3 in c:\\users\\user\\anaconda3\\envs\\practicum\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\envs\\practicum\\lib\\site-packages (from pymystem3) (2.28.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\anaconda3\\envs\\practicum\\lib\\site-packages (from requests->pymystem3) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\envs\\practicum\\lib\\site-packages (from requests->pymystem3) (2023.11.17)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\user\\anaconda3\\envs\\practicum\\lib\\site-packages (from requests->pymystem3) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\envs\\practicum\\lib\\site-packages (from requests->pymystem3) (3.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install pymystem3\n",
    "from pymystem3 import Mystem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Создадим локальную базу данных и подсоединимся к ней.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YBzN0w-pn-Or",
    "outputId": "bc2dcf30-11f4-4d68-d094-c49bfb065d9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SQLAlchemy in c:\\users\\user\\anaconda3\\envs\\practicum\\lib\\site-packages (1.4.39)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\user\\anaconda3\\envs\\practicum\\lib\\site-packages (from SQLAlchemy) (2.0.1)\n",
      "Requirement already satisfied: SQLAlchemy in c:\\users\\user\\anaconda3\\envs\\practicum\\lib\\site-packages (1.4.39)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\user\\anaconda3\\envs\\practicum\\lib\\site-packages (from SQLAlchemy) (2.0.1)\n",
      "Requirement already satisfied: psycopg2 in c:\\users\\user\\anaconda3\\envs\\practicum\\lib\\site-packages (2.9.9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_18740\\1662055909.py:21: SADeprecationWarning: Calling URL() directly is deprecated and will be disabled in a future release.  The public constructor for URL is now the URL.create() method.\n",
      "  engine = create_engine(URL(**DATABASE))\n"
     ]
    }
   ],
   "source": [
    "# database connection\n",
    "!pip install SQLAlchemy\n",
    "!pip install --pre SQLAlchemy\n",
    "!pip install psycopg2\n",
    "\n",
    "import sqlalchemy\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.engine.url import URL\n",
    "\n",
    "DATABASE = {\n",
    "    'drivername': 'postgresql',\n",
    "    'username': 'postgres',\n",
    "    'password': 'password\\'',\n",
    "    'host': 'localhost',\n",
    "    'port': 5433,\n",
    "    'database': 'postgres',\n",
    "    'query': {}\n",
    "}\n",
    "\n",
    "engine = create_engine(URL(**DATABASE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка в базу данных таблиц"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wRdnu5GKoo-e"
   },
   "source": [
    "**Из предварительно загруженных файлов из geonames.org считаем информацию и загрузим в базу данных.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Возьмем таблицу 'alternateNamesV2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\practicum\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3194: DtypeWarning: Columns (8,9) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "alternateNamesV2 = pd.read_csv(\"C:/Users/User/Desktop/DS Python/Geonames/data/alternateNamesV2.txt\", \n",
    "                               delimiter='\\t', \n",
    "                               header=None,\n",
    "                               names = [\n",
    "                               'geonameid', \n",
    "                               'isoLanguage', \n",
    "                               'alternateName', \n",
    "                               'isPreferredName', \n",
    "                               'isShortName', \n",
    "                               'isColloquial', \n",
    "                               'isHistoric',\n",
    "                               'from_period', \n",
    "                               'to_period'    \n",
    "                               ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Познакомимся с таблицей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geonameid</th>\n",
       "      <th>isoLanguage</th>\n",
       "      <th>alternateName</th>\n",
       "      <th>isPreferredName</th>\n",
       "      <th>isShortName</th>\n",
       "      <th>isColloquial</th>\n",
       "      <th>isHistoric</th>\n",
       "      <th>from_period</th>\n",
       "      <th>to_period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17666269</th>\n",
       "      <td>12628281</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Minami-Shimoji</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17666270</th>\n",
       "      <td>12628282</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nakanōgan Hill</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17666271</th>\n",
       "      <td>12628282</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nakanougan Hill</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17666272</th>\n",
       "      <td>12628283</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Okisakishima Ridge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17666273</th>\n",
       "      <td>12628283</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Oki-Sakishima Ridge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          geonameid isoLanguage        alternateName  isPreferredName  \\\n",
       "17666269   12628281         NaN       Minami-Shimoji              NaN   \n",
       "17666270   12628282         NaN       Nakanōgan Hill              NaN   \n",
       "17666271   12628282         NaN      Nakanougan Hill              NaN   \n",
       "17666272   12628283         NaN   Okisakishima Ridge              NaN   \n",
       "17666273   12628283         NaN  Oki-Sakishima Ridge              NaN   \n",
       "\n",
       "          isShortName  isColloquial  isHistoric from_period to_period  \n",
       "17666269          NaN           NaN         NaN         NaN       NaN  \n",
       "17666270          NaN           NaN         NaN         NaN       NaN  \n",
       "17666271          NaN           NaN         NaN         NaN       NaN  \n",
       "17666272          NaN           NaN         NaN         NaN       NaN  \n",
       "17666273          NaN           NaN         NaN         NaN       NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alternateNamesV2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 16035367 entries, 1284819 to 17666273\n",
      "Data columns (total 9 columns):\n",
      " #   Column           Dtype  \n",
      "---  ------           -----  \n",
      " 0   geonameid        int64  \n",
      " 1   isoLanguage      object \n",
      " 2   alternateName    object \n",
      " 3   isPreferredName  float64\n",
      " 4   isShortName      float64\n",
      " 5   isColloquial     float64\n",
      " 6   isHistoric       float64\n",
      " 7   from_period      object \n",
      " 8   to_period        object \n",
      "dtypes: float64(4), int64(1), object(4)\n",
      "memory usage: 1.2+ GB\n"
     ]
    }
   ],
   "source": [
    "alternateNamesV2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим количество пропусков в данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_a412e_row0_col0,#T_a412e_row2_col0{\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_a412e_row1_col0{\n",
       "            background-color:  #c9d7f0;\n",
       "            color:  #000000;\n",
       "        }#T_a412e_row3_col0{\n",
       "            background-color:  #c0282f;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_a412e_row4_col0{\n",
       "            background-color:  #b50927;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_a412e_row5_col0,#T_a412e_row6_col0,#T_a412e_row7_col0,#T_a412e_row8_col0{\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }</style><table id=\"T_a412e_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >0</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_a412e_level0_row0\" class=\"row_heading level0 row0\" >geonameid</th>\n",
       "                        <td id=\"T_a412e_row0_col0\" class=\"data row0 col0\" >0.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a412e_level0_row1\" class=\"row_heading level0 row1\" >isoLanguage</th>\n",
       "                        <td id=\"T_a412e_row1_col0\" class=\"data row1 col0\" >42.650000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a412e_level0_row2\" class=\"row_heading level0 row2\" >alternateName</th>\n",
       "                        <td id=\"T_a412e_row2_col0\" class=\"data row2 col0\" >0.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a412e_level0_row3\" class=\"row_heading level0 row3\" >isPreferredName</th>\n",
       "                        <td id=\"T_a412e_row3_col0\" class=\"data row3 col0\" >96.620000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a412e_level0_row4\" class=\"row_heading level0 row4\" >isShortName</th>\n",
       "                        <td id=\"T_a412e_row4_col0\" class=\"data row4 col0\" >99.280000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a412e_level0_row5\" class=\"row_heading level0 row5\" >isColloquial</th>\n",
       "                        <td id=\"T_a412e_row5_col0\" class=\"data row5 col0\" >99.980000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a412e_level0_row6\" class=\"row_heading level0 row6\" >isHistoric</th>\n",
       "                        <td id=\"T_a412e_row6_col0\" class=\"data row6 col0\" >99.820000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a412e_level0_row7\" class=\"row_heading level0 row7\" >from_period</th>\n",
       "                        <td id=\"T_a412e_row7_col0\" class=\"data row7 col0\" >99.980000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a412e_level0_row8\" class=\"row_heading level0 row8\" >to_period</th>\n",
       "                        <td id=\"T_a412e_row8_col0\" class=\"data row8 col0\" >99.980000</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x20f9ec72a90>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(round(alternateNamesV2.isna().mean()*100,2)).style.background_gradient('coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В столбцах много пропусков, проверим с чем связано."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan,  1.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alternateNamesV2['isShortName'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan,  1.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alternateNamesV2['isColloquial'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan,  1.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alternateNamesV2['isHistoric'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan,  1.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alternateNamesV2['isPreferredName'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вероятнее всего, заполнялись только значения равные 1.0. Чтобы не потерять данные и не удалять строки, все пустые строки заполняю значением 0.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "alternateNamesV2[['isShortName', 'isColloquial', 'isHistoric', 'isPreferredName']] = alternateNamesV2[[\n",
    "    'isShortName', 'isColloquial', 'isHistoric', 'isPreferredName']].fillna(0.0, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_a148a_row0_col0,#T_a148a_row2_col0,#T_a148a_row3_col0,#T_a148a_row4_col0,#T_a148a_row5_col0,#T_a148a_row6_col0{\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_a148a_row1_col0{\n",
       "            background-color:  #c9d7f0;\n",
       "            color:  #000000;\n",
       "        }#T_a148a_row7_col0,#T_a148a_row8_col0{\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }</style><table id=\"T_a148a_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >0</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_a148a_level0_row0\" class=\"row_heading level0 row0\" >geonameid</th>\n",
       "                        <td id=\"T_a148a_row0_col0\" class=\"data row0 col0\" >0.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a148a_level0_row1\" class=\"row_heading level0 row1\" >isoLanguage</th>\n",
       "                        <td id=\"T_a148a_row1_col0\" class=\"data row1 col0\" >42.650000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a148a_level0_row2\" class=\"row_heading level0 row2\" >alternateName</th>\n",
       "                        <td id=\"T_a148a_row2_col0\" class=\"data row2 col0\" >0.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a148a_level0_row3\" class=\"row_heading level0 row3\" >isPreferredName</th>\n",
       "                        <td id=\"T_a148a_row3_col0\" class=\"data row3 col0\" >0.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a148a_level0_row4\" class=\"row_heading level0 row4\" >isShortName</th>\n",
       "                        <td id=\"T_a148a_row4_col0\" class=\"data row4 col0\" >0.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a148a_level0_row5\" class=\"row_heading level0 row5\" >isColloquial</th>\n",
       "                        <td id=\"T_a148a_row5_col0\" class=\"data row5 col0\" >0.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a148a_level0_row6\" class=\"row_heading level0 row6\" >isHistoric</th>\n",
       "                        <td id=\"T_a148a_row6_col0\" class=\"data row6 col0\" >0.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a148a_level0_row7\" class=\"row_heading level0 row7\" >from_period</th>\n",
       "                        <td id=\"T_a148a_row7_col0\" class=\"data row7 col0\" >99.980000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a148a_level0_row8\" class=\"row_heading level0 row8\" >to_period</th>\n",
       "                        <td id=\"T_a148a_row8_col0\" class=\"data row8 col0\" >99.980000</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x210c5b06eb0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(round(alternateNamesV2.isna().mean()*100,2)).style.background_gradient('coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alternateNamesV2['isPreferredName'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Занесем данные из таблицы в базу данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "alternateNamesV2.to_sql(name='alternatename', if_exists = 'replace', con=engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Возьмем таблицу 'countryInfo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "countryinfo = pd.read_csv(\"C:/Users/User/Desktop/DS Python/Geonames/data/countryInfo.txt\", \n",
    "                               delimiter='\\t', \n",
    "                               header=None,\n",
    "                               skiprows=50, \n",
    "                               names = [\n",
    "                               'country_code', \n",
    "                               'iso_alpha3', \n",
    "                               'iso_numeric', \n",
    "                               'fips_code', \n",
    "                               'country', \n",
    "                               'capital', \n",
    "                               'areainsqkm', \n",
    "                               'population', \n",
    "                               'continent', \n",
    "                               'tld', \n",
    "                               'currency_code', \n",
    "                               'currency_name', \n",
    "                               'phone', \n",
    "                               'postal_code_format', \n",
    "                               'postal_code_regex',\n",
    "                               'languages',\n",
    "                               'geonameid', \n",
    "                               'neighbours', \n",
    "                               'equivalent_fips_code'\n",
    "                                   ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Познакомимся с таблицей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 252 entries, 0 to 251\n",
      "Data columns (total 19 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   country_code          251 non-null    object \n",
      " 1   iso_alpha3            252 non-null    object \n",
      " 2   iso_numeric           252 non-null    int64  \n",
      " 3   fips_code             249 non-null    object \n",
      " 4   country               252 non-null    object \n",
      " 5   capital               246 non-null    object \n",
      " 6   areainsqkm            252 non-null    float64\n",
      " 7   population            252 non-null    int64  \n",
      " 8   continent             210 non-null    object \n",
      " 9   tld                   251 non-null    object \n",
      " 10  currency_code         251 non-null    object \n",
      " 11  currency_name         251 non-null    object \n",
      " 12  phone                 247 non-null    object \n",
      " 13  postal_code_format    162 non-null    object \n",
      " 14  postal_code_regex     162 non-null    object \n",
      " 15  languages             249 non-null    object \n",
      " 16  geonameid             252 non-null    int64  \n",
      " 17  neighbours            165 non-null    object \n",
      " 18  equivalent_fips_code  1 non-null      object \n",
      "dtypes: float64(1), int64(3), object(15)\n",
      "memory usage: 37.5+ KB\n"
     ]
    }
   ],
   "source": [
    "countryinfo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_code</th>\n",
       "      <th>iso_alpha3</th>\n",
       "      <th>iso_numeric</th>\n",
       "      <th>fips_code</th>\n",
       "      <th>country</th>\n",
       "      <th>capital</th>\n",
       "      <th>areainsqkm</th>\n",
       "      <th>population</th>\n",
       "      <th>continent</th>\n",
       "      <th>tld</th>\n",
       "      <th>currency_code</th>\n",
       "      <th>currency_name</th>\n",
       "      <th>phone</th>\n",
       "      <th>postal_code_format</th>\n",
       "      <th>postal_code_regex</th>\n",
       "      <th>languages</th>\n",
       "      <th>geonameid</th>\n",
       "      <th>neighbours</th>\n",
       "      <th>equivalent_fips_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AD</td>\n",
       "      <td>AND</td>\n",
       "      <td>20</td>\n",
       "      <td>AN</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>Andorra la Vella</td>\n",
       "      <td>468.0</td>\n",
       "      <td>77006</td>\n",
       "      <td>EU</td>\n",
       "      <td>.ad</td>\n",
       "      <td>EUR</td>\n",
       "      <td>Euro</td>\n",
       "      <td>376</td>\n",
       "      <td>AD###</td>\n",
       "      <td>^(?:AD)*(\\d{3})$</td>\n",
       "      <td>ca</td>\n",
       "      <td>3041565</td>\n",
       "      <td>ES,FR</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AE</td>\n",
       "      <td>ARE</td>\n",
       "      <td>784</td>\n",
       "      <td>AE</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>Abu Dhabi</td>\n",
       "      <td>82880.0</td>\n",
       "      <td>9630959</td>\n",
       "      <td>AS</td>\n",
       "      <td>.ae</td>\n",
       "      <td>AED</td>\n",
       "      <td>Dirham</td>\n",
       "      <td>971</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ar-AE,fa,en,hi,ur</td>\n",
       "      <td>290557</td>\n",
       "      <td>SA,OM</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AF</td>\n",
       "      <td>AFG</td>\n",
       "      <td>4</td>\n",
       "      <td>AF</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Kabul</td>\n",
       "      <td>647500.0</td>\n",
       "      <td>37172386</td>\n",
       "      <td>AS</td>\n",
       "      <td>.af</td>\n",
       "      <td>AFN</td>\n",
       "      <td>Afghani</td>\n",
       "      <td>93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fa-AF,ps,uz-AF,tk</td>\n",
       "      <td>1149361</td>\n",
       "      <td>TM,CN,IR,TJ,PK,UZ</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AG</td>\n",
       "      <td>ATG</td>\n",
       "      <td>28</td>\n",
       "      <td>AC</td>\n",
       "      <td>Antigua and Barbuda</td>\n",
       "      <td>St. John's</td>\n",
       "      <td>443.0</td>\n",
       "      <td>96286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.ag</td>\n",
       "      <td>XCD</td>\n",
       "      <td>Dollar</td>\n",
       "      <td>+1-268</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en-AG</td>\n",
       "      <td>3576396</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AI</td>\n",
       "      <td>AIA</td>\n",
       "      <td>660</td>\n",
       "      <td>AV</td>\n",
       "      <td>Anguilla</td>\n",
       "      <td>The Valley</td>\n",
       "      <td>102.0</td>\n",
       "      <td>13254</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.ai</td>\n",
       "      <td>XCD</td>\n",
       "      <td>Dollar</td>\n",
       "      <td>+1-264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en-AI</td>\n",
       "      <td>3573511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AL</td>\n",
       "      <td>ALB</td>\n",
       "      <td>8</td>\n",
       "      <td>AL</td>\n",
       "      <td>Albania</td>\n",
       "      <td>Tirana</td>\n",
       "      <td>28748.0</td>\n",
       "      <td>2866376</td>\n",
       "      <td>EU</td>\n",
       "      <td>.al</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Lek</td>\n",
       "      <td>355</td>\n",
       "      <td>####</td>\n",
       "      <td>^(\\d{4})$</td>\n",
       "      <td>sq,el</td>\n",
       "      <td>783754</td>\n",
       "      <td>MK,GR,ME,RS,XK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AM</td>\n",
       "      <td>ARM</td>\n",
       "      <td>51</td>\n",
       "      <td>AM</td>\n",
       "      <td>Armenia</td>\n",
       "      <td>Yerevan</td>\n",
       "      <td>29800.0</td>\n",
       "      <td>2951776</td>\n",
       "      <td>AS</td>\n",
       "      <td>.am</td>\n",
       "      <td>AMD</td>\n",
       "      <td>Dram</td>\n",
       "      <td>374</td>\n",
       "      <td>######</td>\n",
       "      <td>^(\\d{6})$</td>\n",
       "      <td>hy</td>\n",
       "      <td>174982</td>\n",
       "      <td>GE,IR,AZ,TR</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AO</td>\n",
       "      <td>AGO</td>\n",
       "      <td>24</td>\n",
       "      <td>AO</td>\n",
       "      <td>Angola</td>\n",
       "      <td>Luanda</td>\n",
       "      <td>1246700.0</td>\n",
       "      <td>30809762</td>\n",
       "      <td>AF</td>\n",
       "      <td>.ao</td>\n",
       "      <td>AOA</td>\n",
       "      <td>Kwanza</td>\n",
       "      <td>244</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt-AO</td>\n",
       "      <td>3351879</td>\n",
       "      <td>CD,NA,ZM,CG</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AQ</td>\n",
       "      <td>ATA</td>\n",
       "      <td>10</td>\n",
       "      <td>AY</td>\n",
       "      <td>Antarctica</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14000000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>AN</td>\n",
       "      <td>.aq</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6697173</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AR</td>\n",
       "      <td>ARG</td>\n",
       "      <td>32</td>\n",
       "      <td>AR</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Buenos Aires</td>\n",
       "      <td>2766890.0</td>\n",
       "      <td>44494502</td>\n",
       "      <td>SA</td>\n",
       "      <td>.ar</td>\n",
       "      <td>ARS</td>\n",
       "      <td>Peso</td>\n",
       "      <td>54</td>\n",
       "      <td>@####@@@</td>\n",
       "      <td>^[A-Z]?\\d{4}[A-Z]{0,3}$</td>\n",
       "      <td>es-AR,en,it,de,fr,gn</td>\n",
       "      <td>3865483</td>\n",
       "      <td>CL,BO,UY,PY,BR</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country_code iso_alpha3  iso_numeric fips_code               country  \\\n",
       "0           AD        AND           20        AN               Andorra   \n",
       "1           AE        ARE          784        AE  United Arab Emirates   \n",
       "2           AF        AFG            4        AF           Afghanistan   \n",
       "3           AG        ATG           28        AC   Antigua and Barbuda   \n",
       "4           AI        AIA          660        AV              Anguilla   \n",
       "5           AL        ALB            8        AL               Albania   \n",
       "6           AM        ARM           51        AM               Armenia   \n",
       "7           AO        AGO           24        AO                Angola   \n",
       "8           AQ        ATA           10        AY            Antarctica   \n",
       "9           AR        ARG           32        AR             Argentina   \n",
       "\n",
       "            capital  areainsqkm  population continent  tld currency_code  \\\n",
       "0  Andorra la Vella       468.0       77006        EU  .ad           EUR   \n",
       "1         Abu Dhabi     82880.0     9630959        AS  .ae           AED   \n",
       "2             Kabul    647500.0    37172386        AS  .af           AFN   \n",
       "3        St. John's       443.0       96286       NaN  .ag           XCD   \n",
       "4        The Valley       102.0       13254       NaN  .ai           XCD   \n",
       "5            Tirana     28748.0     2866376        EU  .al           ALL   \n",
       "6           Yerevan     29800.0     2951776        AS  .am           AMD   \n",
       "7            Luanda   1246700.0    30809762        AF  .ao           AOA   \n",
       "8               NaN  14000000.0           0        AN  .aq           NaN   \n",
       "9      Buenos Aires   2766890.0    44494502        SA  .ar           ARS   \n",
       "\n",
       "  currency_name   phone postal_code_format        postal_code_regex  \\\n",
       "0          Euro     376              AD###         ^(?:AD)*(\\d{3})$   \n",
       "1        Dirham     971                NaN                      NaN   \n",
       "2       Afghani      93                NaN                      NaN   \n",
       "3        Dollar  +1-268                NaN                      NaN   \n",
       "4        Dollar  +1-264                NaN                      NaN   \n",
       "5           Lek     355               ####                ^(\\d{4})$   \n",
       "6          Dram     374             ######                ^(\\d{6})$   \n",
       "7        Kwanza     244                NaN                      NaN   \n",
       "8           NaN     NaN                NaN                      NaN   \n",
       "9          Peso      54           @####@@@  ^[A-Z]?\\d{4}[A-Z]{0,3}$   \n",
       "\n",
       "              languages  geonameid         neighbours equivalent_fips_code  \n",
       "0                    ca    3041565              ES,FR                  NaN  \n",
       "1     ar-AE,fa,en,hi,ur     290557              SA,OM                  NaN  \n",
       "2     fa-AF,ps,uz-AF,tk    1149361  TM,CN,IR,TJ,PK,UZ                  NaN  \n",
       "3                 en-AG    3576396                NaN                  NaN  \n",
       "4                 en-AI    3573511                NaN                  NaN  \n",
       "5                 sq,el     783754     MK,GR,ME,RS,XK                  NaN  \n",
       "6                    hy     174982        GE,IR,AZ,TR                  NaN  \n",
       "7                 pt-AO    3351879        CD,NA,ZM,CG                  NaN  \n",
       "8                   NaN    6697173                NaN                  NaN  \n",
       "9  es-AR,en,it,de,fr,gn    3865483     CL,BO,UY,PY,BR                  NaN  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countryinfo.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим количество пропусков в данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_cfd0c_row0_col0,#T_cfd0c_row9_col0,#T_cfd0c_row10_col0,#T_cfd0c_row11_col0{\n",
       "            background-color:  #3c4ec2;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_cfd0c_row1_col0,#T_cfd0c_row2_col0,#T_cfd0c_row4_col0,#T_cfd0c_row6_col0,#T_cfd0c_row7_col0,#T_cfd0c_row16_col0{\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_cfd0c_row3_col0,#T_cfd0c_row15_col0{\n",
       "            background-color:  #3e51c5;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_cfd0c_row5_col0{\n",
       "            background-color:  #4257c9;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_cfd0c_row8_col0{\n",
       "            background-color:  #6f92f3;\n",
       "            color:  #000000;\n",
       "        }#T_cfd0c_row12_col0{\n",
       "            background-color:  #4055c8;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_cfd0c_row13_col0,#T_cfd0c_row14_col0{\n",
       "            background-color:  #b2ccfb;\n",
       "            color:  #000000;\n",
       "        }#T_cfd0c_row17_col0{\n",
       "            background-color:  #aec9fc;\n",
       "            color:  #000000;\n",
       "        }#T_cfd0c_row18_col0{\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }</style><table id=\"T_cfd0c_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >0</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_cfd0c_level0_row0\" class=\"row_heading level0 row0\" >country_code</th>\n",
       "                        <td id=\"T_cfd0c_row0_col0\" class=\"data row0 col0\" >0.400000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cfd0c_level0_row1\" class=\"row_heading level0 row1\" >iso_alpha3</th>\n",
       "                        <td id=\"T_cfd0c_row1_col0\" class=\"data row1 col0\" >0.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cfd0c_level0_row2\" class=\"row_heading level0 row2\" >iso_numeric</th>\n",
       "                        <td id=\"T_cfd0c_row2_col0\" class=\"data row2 col0\" >0.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cfd0c_level0_row3\" class=\"row_heading level0 row3\" >fips_code</th>\n",
       "                        <td id=\"T_cfd0c_row3_col0\" class=\"data row3 col0\" >1.190000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cfd0c_level0_row4\" class=\"row_heading level0 row4\" >country</th>\n",
       "                        <td id=\"T_cfd0c_row4_col0\" class=\"data row4 col0\" >0.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cfd0c_level0_row5\" class=\"row_heading level0 row5\" >capital</th>\n",
       "                        <td id=\"T_cfd0c_row5_col0\" class=\"data row5 col0\" >2.380000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cfd0c_level0_row6\" class=\"row_heading level0 row6\" >areainsqkm</th>\n",
       "                        <td id=\"T_cfd0c_row6_col0\" class=\"data row6 col0\" >0.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cfd0c_level0_row7\" class=\"row_heading level0 row7\" >population</th>\n",
       "                        <td id=\"T_cfd0c_row7_col0\" class=\"data row7 col0\" >0.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cfd0c_level0_row8\" class=\"row_heading level0 row8\" >continent</th>\n",
       "                        <td id=\"T_cfd0c_row8_col0\" class=\"data row8 col0\" >16.670000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cfd0c_level0_row9\" class=\"row_heading level0 row9\" >tld</th>\n",
       "                        <td id=\"T_cfd0c_row9_col0\" class=\"data row9 col0\" >0.400000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cfd0c_level0_row10\" class=\"row_heading level0 row10\" >currency_code</th>\n",
       "                        <td id=\"T_cfd0c_row10_col0\" class=\"data row10 col0\" >0.400000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cfd0c_level0_row11\" class=\"row_heading level0 row11\" >currency_name</th>\n",
       "                        <td id=\"T_cfd0c_row11_col0\" class=\"data row11 col0\" >0.400000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cfd0c_level0_row12\" class=\"row_heading level0 row12\" >phone</th>\n",
       "                        <td id=\"T_cfd0c_row12_col0\" class=\"data row12 col0\" >1.980000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cfd0c_level0_row13\" class=\"row_heading level0 row13\" >postal_code_format</th>\n",
       "                        <td id=\"T_cfd0c_row13_col0\" class=\"data row13 col0\" >35.710000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cfd0c_level0_row14\" class=\"row_heading level0 row14\" >postal_code_regex</th>\n",
       "                        <td id=\"T_cfd0c_row14_col0\" class=\"data row14 col0\" >35.710000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cfd0c_level0_row15\" class=\"row_heading level0 row15\" >languages</th>\n",
       "                        <td id=\"T_cfd0c_row15_col0\" class=\"data row15 col0\" >1.190000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cfd0c_level0_row16\" class=\"row_heading level0 row16\" >geonameid</th>\n",
       "                        <td id=\"T_cfd0c_row16_col0\" class=\"data row16 col0\" >0.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cfd0c_level0_row17\" class=\"row_heading level0 row17\" >neighbours</th>\n",
       "                        <td id=\"T_cfd0c_row17_col0\" class=\"data row17 col0\" >34.520000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cfd0c_level0_row18\" class=\"row_heading level0 row18\" >equivalent_fips_code</th>\n",
       "                        <td id=\"T_cfd0c_row18_col0\" class=\"data row18 col0\" >99.600000</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x215fd67bac0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(round(countryinfo.isna().mean()*100,2)).style.background_gradient('coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Занесем данные из таблицы в базу данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "countryinfo.to_sql(name='countryinfo', if_exists = 'replace', con=engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Возьмем таблицу 'admin1CodesASCII'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "admintocodes = pd.read_csv(\"C:/Users/User/Desktop/DS Python/Geonames/data/admin1CodesASCII.txt\", \n",
    "                               delimiter='\\t', \n",
    "                               header=None, \n",
    "                               names = [\n",
    "                               'code', \n",
    "                               'region', \n",
    "                               'ascii_region', \n",
    "                               'geonameid'\n",
    "                               ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Познакомимся с таблицей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>region</th>\n",
       "      <th>ascii_region</th>\n",
       "      <th>geonameid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AD.06</td>\n",
       "      <td>Sant Julià de Loria</td>\n",
       "      <td>Sant Julia de Loria</td>\n",
       "      <td>3039162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AD.05</td>\n",
       "      <td>Ordino</td>\n",
       "      <td>Ordino</td>\n",
       "      <td>3039676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AD.04</td>\n",
       "      <td>La Massana</td>\n",
       "      <td>La Massana</td>\n",
       "      <td>3040131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AD.03</td>\n",
       "      <td>Encamp</td>\n",
       "      <td>Encamp</td>\n",
       "      <td>3040684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AD.02</td>\n",
       "      <td>Canillo</td>\n",
       "      <td>Canillo</td>\n",
       "      <td>3041203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AD.07</td>\n",
       "      <td>Andorra la Vella</td>\n",
       "      <td>Andorra la Vella</td>\n",
       "      <td>3041566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AD.08</td>\n",
       "      <td>Escaldes-Engordany</td>\n",
       "      <td>Escaldes-Engordany</td>\n",
       "      <td>3338529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AE.07</td>\n",
       "      <td>Imārat Umm al Qaywayn</td>\n",
       "      <td>Imarat Umm al Qaywayn</td>\n",
       "      <td>290595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AE.05</td>\n",
       "      <td>Raʼs al Khaymah</td>\n",
       "      <td>Imarat Ra's al Khaymah</td>\n",
       "      <td>291075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AE.03</td>\n",
       "      <td>Dubai</td>\n",
       "      <td>Dubai</td>\n",
       "      <td>292224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    code                 region            ascii_region  geonameid\n",
       "0  AD.06    Sant Julià de Loria     Sant Julia de Loria    3039162\n",
       "1  AD.05                 Ordino                  Ordino    3039676\n",
       "2  AD.04             La Massana              La Massana    3040131\n",
       "3  AD.03                 Encamp                  Encamp    3040684\n",
       "4  AD.02                Canillo                 Canillo    3041203\n",
       "5  AD.07       Andorra la Vella        Andorra la Vella    3041566\n",
       "6  AD.08     Escaldes-Engordany      Escaldes-Engordany    3338529\n",
       "7  AE.07  Imārat Umm al Qaywayn   Imarat Umm al Qaywayn     290595\n",
       "8  AE.05        Raʼs al Khaymah  Imarat Ra's al Khaymah     291075\n",
       "9  AE.03                  Dubai                   Dubai     292224"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admintocodes.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим количество пропусков в данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_0dc9c_row0_col0,#T_0dc9c_row1_col0,#T_0dc9c_row2_col0,#T_0dc9c_row3_col0{\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }</style><table id=\"T_0dc9c_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >0</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_0dc9c_level0_row0\" class=\"row_heading level0 row0\" >code</th>\n",
       "                        <td id=\"T_0dc9c_row0_col0\" class=\"data row0 col0\" >0.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0dc9c_level0_row1\" class=\"row_heading level0 row1\" >region</th>\n",
       "                        <td id=\"T_0dc9c_row1_col0\" class=\"data row1 col0\" >0.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0dc9c_level0_row2\" class=\"row_heading level0 row2\" >ascii_region</th>\n",
       "                        <td id=\"T_0dc9c_row2_col0\" class=\"data row2 col0\" >0.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0dc9c_level0_row3\" class=\"row_heading level0 row3\" >geonameid</th>\n",
       "                        <td id=\"T_0dc9c_row3_col0\" class=\"data row3 col0\" >0.000000</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x215fd67b1c0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(round(admintocodes.isna().mean()*100,2)).style.background_gradient('coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Занесем данные из таблицы в базу данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "admintocodes.to_sql(name='admintocodes', if_exists = 'replace', con=engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Возьмем таблицу 'cities15000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities15000 = pd.read_csv(\"C:/Users/User/Desktop/DS Python/Geonames/data/cities15000.txt\", \n",
    "                               delimiter='\\t', \n",
    "                               header=None,\n",
    "                               names = [\n",
    "                               'geonameid', \n",
    "                               'name', \n",
    "                               'asciiname', \n",
    "                               'alternatenames', \n",
    "                               'latitude', \n",
    "                               'longitude', \n",
    "                               'feature_class',\n",
    "                               'feature_code',\n",
    "                               'country_code', \n",
    "                               'cc2',\n",
    "                               'admin1_code', \n",
    "                               'admin2_code', \n",
    "                               'admin3_code', \n",
    "                               'admin4_code', \n",
    "                               'population',\n",
    "                               'elevation',\n",
    "                               'dem', \n",
    "                               'timezone',\n",
    "                               'modification_date' \n",
    "                               ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Познакомимся с таблицей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geonameid</th>\n",
       "      <th>name</th>\n",
       "      <th>asciiname</th>\n",
       "      <th>alternatenames</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>feature_class</th>\n",
       "      <th>feature_code</th>\n",
       "      <th>country_code</th>\n",
       "      <th>cc2</th>\n",
       "      <th>admin1_code</th>\n",
       "      <th>admin2_code</th>\n",
       "      <th>admin3_code</th>\n",
       "      <th>admin4_code</th>\n",
       "      <th>population</th>\n",
       "      <th>elevation</th>\n",
       "      <th>dem</th>\n",
       "      <th>timezone</th>\n",
       "      <th>modification_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3040051</td>\n",
       "      <td>les Escaldes</td>\n",
       "      <td>les Escaldes</td>\n",
       "      <td>Ehskal'des-Ehndzhordani,Escaldes,Escaldes-Engo...</td>\n",
       "      <td>42.50729</td>\n",
       "      <td>1.53414</td>\n",
       "      <td>P</td>\n",
       "      <td>PPLA</td>\n",
       "      <td>AD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15853</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1033</td>\n",
       "      <td>Europe/Andorra</td>\n",
       "      <td>2008-10-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3041563</td>\n",
       "      <td>Andorra la Vella</td>\n",
       "      <td>Andorra la Vella</td>\n",
       "      <td>ALV,Ando-la-Vyey,Andora,Andora la Vela,Andora ...</td>\n",
       "      <td>42.50779</td>\n",
       "      <td>1.52109</td>\n",
       "      <td>P</td>\n",
       "      <td>PPLC</td>\n",
       "      <td>AD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20430</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1037</td>\n",
       "      <td>Europe/Andorra</td>\n",
       "      <td>2020-03-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>290594</td>\n",
       "      <td>Umm Al Quwain City</td>\n",
       "      <td>Umm Al Quwain City</td>\n",
       "      <td>Oumm al Qaiwain,Oumm al Qaïwaïn,Um al Kawain,U...</td>\n",
       "      <td>25.56473</td>\n",
       "      <td>55.55517</td>\n",
       "      <td>P</td>\n",
       "      <td>PPLA</td>\n",
       "      <td>AE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62747</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>Asia/Dubai</td>\n",
       "      <td>2019-10-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>291074</td>\n",
       "      <td>Ras Al Khaimah City</td>\n",
       "      <td>Ras Al Khaimah City</td>\n",
       "      <td>Julfa,Khaimah,RAK City,RKT,Ra's al Khaymah,Ra'...</td>\n",
       "      <td>25.78953</td>\n",
       "      <td>55.94320</td>\n",
       "      <td>P</td>\n",
       "      <td>PPLA</td>\n",
       "      <td>AE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>351943</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>Asia/Dubai</td>\n",
       "      <td>2019-09-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>291580</td>\n",
       "      <td>Zayed City</td>\n",
       "      <td>Zayed City</td>\n",
       "      <td>Bid' Zayed,Bid’ Zayed,Madinat Za'id,Madinat Za...</td>\n",
       "      <td>23.65416</td>\n",
       "      <td>53.70522</td>\n",
       "      <td>P</td>\n",
       "      <td>PPL</td>\n",
       "      <td>AE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01</td>\n",
       "      <td>103</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63482</td>\n",
       "      <td>NaN</td>\n",
       "      <td>118</td>\n",
       "      <td>Asia/Dubai</td>\n",
       "      <td>2019-10-24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   geonameid                 name            asciiname  \\\n",
       "0    3040051         les Escaldes         les Escaldes   \n",
       "1    3041563     Andorra la Vella     Andorra la Vella   \n",
       "2     290594   Umm Al Quwain City   Umm Al Quwain City   \n",
       "3     291074  Ras Al Khaimah City  Ras Al Khaimah City   \n",
       "4     291580           Zayed City           Zayed City   \n",
       "\n",
       "                                      alternatenames  latitude  longitude  \\\n",
       "0  Ehskal'des-Ehndzhordani,Escaldes,Escaldes-Engo...  42.50729    1.53414   \n",
       "1  ALV,Ando-la-Vyey,Andora,Andora la Vela,Andora ...  42.50779    1.52109   \n",
       "2  Oumm al Qaiwain,Oumm al Qaïwaïn,Um al Kawain,U...  25.56473   55.55517   \n",
       "3  Julfa,Khaimah,RAK City,RKT,Ra's al Khaymah,Ra'...  25.78953   55.94320   \n",
       "4  Bid' Zayed,Bid’ Zayed,Madinat Za'id,Madinat Za...  23.65416   53.70522   \n",
       "\n",
       "  feature_class feature_code country_code  cc2 admin1_code admin2_code  \\\n",
       "0             P         PPLA           AD  NaN          08         NaN   \n",
       "1             P         PPLC           AD  NaN          07         NaN   \n",
       "2             P         PPLA           AE  NaN          07         NaN   \n",
       "3             P         PPLA           AE  NaN          05         NaN   \n",
       "4             P          PPL           AE  NaN          01         103   \n",
       "\n",
       "  admin3_code admin4_code  population  elevation   dem        timezone  \\\n",
       "0         NaN         NaN       15853        NaN  1033  Europe/Andorra   \n",
       "1         NaN         NaN       20430        NaN  1037  Europe/Andorra   \n",
       "2         NaN         NaN       62747        NaN     2      Asia/Dubai   \n",
       "3         NaN         NaN      351943        NaN     2      Asia/Dubai   \n",
       "4         NaN         NaN       63482        NaN   118      Asia/Dubai   \n",
       "\n",
       "  modification_date  \n",
       "0        2008-10-15  \n",
       "1        2020-03-03  \n",
       "2        2019-10-24  \n",
       "3        2019-09-09  \n",
       "4        2019-10-24  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities15000.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities15000['concat_code'] = cities15000['country_code'] + '.' + cities15000['admin1_code']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим количество пропусков в данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_91828_row0_col0,#T_91828_row1_col0,#T_91828_row2_col0,#T_91828_row4_col0,#T_91828_row5_col0,#T_91828_row6_col0,#T_91828_row7_col0,#T_91828_row8_col0,#T_91828_row10_col0,#T_91828_row14_col0,#T_91828_row16_col0,#T_91828_row17_col0,#T_91828_row18_col0,#T_91828_row19_col0{\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_91828_row3_col0{\n",
       "            background-color:  #5470de;\n",
       "            color:  #000000;\n",
       "        }#T_91828_row9_col0{\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_91828_row11_col0{\n",
       "            background-color:  #7597f6;\n",
       "            color:  #000000;\n",
       "        }#T_91828_row12_col0{\n",
       "            background-color:  #f7b194;\n",
       "            color:  #000000;\n",
       "        }#T_91828_row13_col0{\n",
       "            background-color:  #d55042;\n",
       "            color:  #000000;\n",
       "        }#T_91828_row15_col0{\n",
       "            background-color:  #e57058;\n",
       "            color:  #000000;\n",
       "        }</style><table id=\"T_91828_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >0</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_91828_level0_row0\" class=\"row_heading level0 row0\" >geonameid</th>\n",
       "                        <td id=\"T_91828_row0_col0\" class=\"data row0 col0\" >0.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_91828_level0_row1\" class=\"row_heading level0 row1\" >name</th>\n",
       "                        <td id=\"T_91828_row1_col0\" class=\"data row1 col0\" >0.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_91828_level0_row2\" class=\"row_heading level0 row2\" >asciiname</th>\n",
       "                        <td id=\"T_91828_row2_col0\" class=\"data row2 col0\" >0.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_91828_level0_row3\" class=\"row_heading level0 row3\" >alternatenames</th>\n",
       "                        <td id=\"T_91828_row3_col0\" class=\"data row3 col0\" >8.510000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_91828_level0_row4\" class=\"row_heading level0 row4\" >latitude</th>\n",
       "                        <td id=\"T_91828_row4_col0\" class=\"data row4 col0\" >0.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_91828_level0_row5\" class=\"row_heading level0 row5\" >longitude</th>\n",
       "                        <td id=\"T_91828_row5_col0\" class=\"data row5 col0\" >0.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_91828_level0_row6\" class=\"row_heading level0 row6\" >feature_class</th>\n",
       "                        <td id=\"T_91828_row6_col0\" class=\"data row6 col0\" >0.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_91828_level0_row7\" class=\"row_heading level0 row7\" >feature_code</th>\n",
       "                        <td id=\"T_91828_row7_col0\" class=\"data row7 col0\" >0.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_91828_level0_row8\" class=\"row_heading level0 row8\" >country_code</th>\n",
       "                        <td id=\"T_91828_row8_col0\" class=\"data row8 col0\" >0.050000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_91828_level0_row9\" class=\"row_heading level0 row9\" >cc2</th>\n",
       "                        <td id=\"T_91828_row9_col0\" class=\"data row9 col0\" >99.950000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_91828_level0_row10\" class=\"row_heading level0 row10\" >admin1_code</th>\n",
       "                        <td id=\"T_91828_row10_col0\" class=\"data row10 col0\" >0.030000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_91828_level0_row11\" class=\"row_heading level0 row11\" >admin2_code</th>\n",
       "                        <td id=\"T_91828_row11_col0\" class=\"data row11 col0\" >18.110000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_91828_level0_row12\" class=\"row_heading level0 row12\" >admin3_code</th>\n",
       "                        <td id=\"T_91828_row12_col0\" class=\"data row12 col0\" >68.410000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_91828_level0_row13\" class=\"row_heading level0 row13\" >admin4_code</th>\n",
       "                        <td id=\"T_91828_row13_col0\" class=\"data row13 col0\" >90.240000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_91828_level0_row14\" class=\"row_heading level0 row14\" >population</th>\n",
       "                        <td id=\"T_91828_row14_col0\" class=\"data row14 col0\" >0.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_91828_level0_row15\" class=\"row_heading level0 row15\" >elevation</th>\n",
       "                        <td id=\"T_91828_row15_col0\" class=\"data row15 col0\" >84.200000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_91828_level0_row16\" class=\"row_heading level0 row16\" >dem</th>\n",
       "                        <td id=\"T_91828_row16_col0\" class=\"data row16 col0\" >0.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_91828_level0_row17\" class=\"row_heading level0 row17\" >timezone</th>\n",
       "                        <td id=\"T_91828_row17_col0\" class=\"data row17 col0\" >0.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_91828_level0_row18\" class=\"row_heading level0 row18\" >modification_date</th>\n",
       "                        <td id=\"T_91828_row18_col0\" class=\"data row18 col0\" >0.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_91828_level0_row19\" class=\"row_heading level0 row19\" >concat_code</th>\n",
       "                        <td id=\"T_91828_row19_col0\" class=\"data row19 col0\" >0.080000</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x215fd66cf40>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(round(cities15000.isna().mean()*100,2)).style.background_gradient('coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Занесем данные из таблицы в базу данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities15000.to_sql(name='cities15000', if_exists = 'replace', con=engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выгрузка из базы данных требуемого запроса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 686
    },
    "id": "H_rDIuDooTnz",
    "outputId": "b7669bfa-771e-4c0b-e1c7-bd31149266a7",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "query = '''SELECT c.geonameid, \n",
    "                  c.name, \n",
    "                  c.asciiname, \n",
    "                  c.alternatenames, \n",
    "                  c.population,\n",
    "                  i.country,\n",
    "                  c.country_code,\n",
    "                  c.admin1_code,\n",
    "                  c.concat_code,\n",
    "                  a.region,  \n",
    "                  a.ascii_region\n",
    "           FROM cities15000 AS c\n",
    "           LEFT JOIN countryinfo AS i ON c.country_code = i.country_code\n",
    "           LEFT JOIN admintocodes AS a ON c.concat_code = a.code\n",
    "           WHERE c.country_code in ('RU',\n",
    "                                  'KZ',\n",
    "                                  'BY',\n",
    "                                  'AM',\n",
    "                                  'KG',\n",
    "                                  'RS',\n",
    "                                  'TR');         \n",
    "                                \n",
    "'''\n",
    "\n",
    "\n",
    "corpus_rus = pd.read_sql_query(query, con=engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим нашу выгруженную таблицу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geonameid</th>\n",
       "      <th>name</th>\n",
       "      <th>asciiname</th>\n",
       "      <th>alternatenames</th>\n",
       "      <th>population</th>\n",
       "      <th>country</th>\n",
       "      <th>country_code</th>\n",
       "      <th>admin1_code</th>\n",
       "      <th>concat_code</th>\n",
       "      <th>region</th>\n",
       "      <th>ascii_region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>616435</td>\n",
       "      <td>Masis</td>\n",
       "      <td>Masis</td>\n",
       "      <td>Hrazdan,Masis,Narimanlu,Razdan,Takhanshalu,Tok...</td>\n",
       "      <td>18911</td>\n",
       "      <td>Armenia</td>\n",
       "      <td>AM</td>\n",
       "      <td>02</td>\n",
       "      <td>AM.02</td>\n",
       "      <td>Ararat</td>\n",
       "      <td>Ararat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>174991</td>\n",
       "      <td>Ararat</td>\n",
       "      <td>Ararat</td>\n",
       "      <td>Ararat,Araratas,Ararato,Davalinskiy Tsemzavod,...</td>\n",
       "      <td>28832</td>\n",
       "      <td>Armenia</td>\n",
       "      <td>AM</td>\n",
       "      <td>02</td>\n",
       "      <td>AM.02</td>\n",
       "      <td>Ararat</td>\n",
       "      <td>Ararat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>174979</td>\n",
       "      <td>Artashat</td>\n",
       "      <td>Artashat</td>\n",
       "      <td>Artachat,Artasat,Artasatas,Artasato,Artaschat,...</td>\n",
       "      <td>20562</td>\n",
       "      <td>Armenia</td>\n",
       "      <td>AM</td>\n",
       "      <td>02</td>\n",
       "      <td>AM.02</td>\n",
       "      <td>Ararat</td>\n",
       "      <td>Ararat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>174972</td>\n",
       "      <td>Hats’avan</td>\n",
       "      <td>Hats'avan</td>\n",
       "      <td>Acavan,Atsavan,Hats'avan,Hats’avan,Sisian,Ацав...</td>\n",
       "      <td>15208</td>\n",
       "      <td>Armenia</td>\n",
       "      <td>AM</td>\n",
       "      <td>08</td>\n",
       "      <td>AM.08</td>\n",
       "      <td>Syunik</td>\n",
       "      <td>Syunik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>174895</td>\n",
       "      <td>Goris</td>\n",
       "      <td>Goris</td>\n",
       "      <td>Geryusy,Goris,Горис,Գորիս</td>\n",
       "      <td>20379</td>\n",
       "      <td>Armenia</td>\n",
       "      <td>AM</td>\n",
       "      <td>08</td>\n",
       "      <td>AM.08</td>\n",
       "      <td>Syunik</td>\n",
       "      <td>Syunik</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   geonameid       name  asciiname  \\\n",
       "0     616435      Masis      Masis   \n",
       "1     174991     Ararat     Ararat   \n",
       "2     174979   Artashat   Artashat   \n",
       "3     174972  Hats’avan  Hats'avan   \n",
       "4     174895      Goris      Goris   \n",
       "\n",
       "                                      alternatenames  population  country  \\\n",
       "0  Hrazdan,Masis,Narimanlu,Razdan,Takhanshalu,Tok...       18911  Armenia   \n",
       "1  Ararat,Araratas,Ararato,Davalinskiy Tsemzavod,...       28832  Armenia   \n",
       "2  Artachat,Artasat,Artasatas,Artasato,Artaschat,...       20562  Armenia   \n",
       "3  Acavan,Atsavan,Hats'avan,Hats’avan,Sisian,Ацав...       15208  Armenia   \n",
       "4                          Geryusy,Goris,Горис,Գորիս       20379  Armenia   \n",
       "\n",
       "  country_code admin1_code concat_code  region ascii_region  \n",
       "0           AM          02       AM.02  Ararat       Ararat  \n",
       "1           AM          02       AM.02  Ararat       Ararat  \n",
       "2           AM          02       AM.02  Ararat       Ararat  \n",
       "3           AM          08       AM.08  Syunik       Syunik  \n",
       "4           AM          08       AM.08  Syunik       Syunik  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_rus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Так как некоторые расчеты будут проводится с использование gpu, чтобы сразу загрузить данные на сервис и работать над задачей, сохраним таблицу.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В файле *corpus.csv* будут храниться все выгруженные значения новой таблицы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_rus.to_csv(r\"C:/Users/User/Desktop/DS Python/Geonames/data/corpus.csv\", index=False, sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сразу заменим пропуски на пустые строки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_rus['alternatenames'] = [name if name is not None else '' for name in corpus_rus['alternatenames']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Метод векторизации слова CountVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдем расстояние между искомым словом и ближайшим словом из текста, приводя их к набору чисел.\n",
    "\n",
    "Создадим экземпляр класса CountVectorizer()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# анализировать будем отдельные буквы и n-граммы\n",
    "vectorizer = CountVectorizer(analyzer='char', ngram_range=(2,4)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим экземпляр кастомного класса CountVec()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_mod = CountVec()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для проверки работы скрипта введем запрашиваемый город и количество ниболее близких названий городов. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "city = 'влодекасток' # запрашиваемый город"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 3 # количество близких названий городов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для подбора наиболее подходящих названий с geonames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top = vec_mod.get_cos(city, \n",
    "                       corpus_rus[['geonameid', 'asciiname', 'alternatenames', 'country', 'region']], \n",
    "                       vectorizer, \n",
    "                       num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'geonameid': 2013348,\n",
       "  'asciiname': 'Vladivostok',\n",
       "  'region': 'Primorye',\n",
       "  'country': 'Russia',\n",
       "  'cosine_sim': 0.5773503184318542},\n",
       " {'geonameid': 743882,\n",
       "  'asciiname': 'Kastamonu',\n",
       "  'region': 'Kastamonu',\n",
       "  'country': 'Turkey',\n",
       "  'cosine_sim': 0.471404492855072},\n",
       " {'geonameid': 1520240,\n",
       "  'asciiname': 'Pavlodar',\n",
       "  'region': 'Pavlodar Region',\n",
       "  'country': 'Kazakhstan',\n",
       "  'cosine_sim': 0.471404492855072}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Метод использования предобученной модели из SentenceTransformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обработаем значения в таблице *corpus*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удаляем пропущенные значения из таблицы\n",
    "corpus = corpus_rus.dropna()\n",
    "# Разделяем значения в столбце 'alternatenames'\n",
    "corpus.alternatenames = corpus.alternatenames.str.split(',')\n",
    "# Приводим к виду 1 наименование asciiname = 1 наименование alternatenames\n",
    "corpus = corpus.explode('alternatenames')\n",
    "# Удаляем совпадающие значения в столбцах\n",
    "corpus = corpus[corpus.asciiname!=corpus.alternatenames]\n",
    "# Удаляем парные дубликаты из двух столбцов\n",
    "corpus = corpus.drop_duplicates(subset=['asciiname', 'alternatenames'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выведем первые 5 строк преобразованной таблицы и размер на экран.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geonameid</th>\n",
       "      <th>name</th>\n",
       "      <th>asciiname</th>\n",
       "      <th>alternatenames</th>\n",
       "      <th>population</th>\n",
       "      <th>country</th>\n",
       "      <th>country_code</th>\n",
       "      <th>admin1_code</th>\n",
       "      <th>concat_code</th>\n",
       "      <th>region</th>\n",
       "      <th>ascii_region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>616435</td>\n",
       "      <td>Masis</td>\n",
       "      <td>Masis</td>\n",
       "      <td>Hrazdan</td>\n",
       "      <td>18911</td>\n",
       "      <td>Armenia</td>\n",
       "      <td>AM</td>\n",
       "      <td>02</td>\n",
       "      <td>AM.02</td>\n",
       "      <td>Ararat</td>\n",
       "      <td>Ararat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>616435</td>\n",
       "      <td>Masis</td>\n",
       "      <td>Masis</td>\n",
       "      <td>Narimanlu</td>\n",
       "      <td>18911</td>\n",
       "      <td>Armenia</td>\n",
       "      <td>AM</td>\n",
       "      <td>02</td>\n",
       "      <td>AM.02</td>\n",
       "      <td>Ararat</td>\n",
       "      <td>Ararat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>616435</td>\n",
       "      <td>Masis</td>\n",
       "      <td>Masis</td>\n",
       "      <td>Razdan</td>\n",
       "      <td>18911</td>\n",
       "      <td>Armenia</td>\n",
       "      <td>AM</td>\n",
       "      <td>02</td>\n",
       "      <td>AM.02</td>\n",
       "      <td>Ararat</td>\n",
       "      <td>Ararat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>616435</td>\n",
       "      <td>Masis</td>\n",
       "      <td>Masis</td>\n",
       "      <td>Takhanshalu</td>\n",
       "      <td>18911</td>\n",
       "      <td>Armenia</td>\n",
       "      <td>AM</td>\n",
       "      <td>02</td>\n",
       "      <td>AM.02</td>\n",
       "      <td>Ararat</td>\n",
       "      <td>Ararat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>616435</td>\n",
       "      <td>Masis</td>\n",
       "      <td>Masis</td>\n",
       "      <td>Tokhanshalu</td>\n",
       "      <td>18911</td>\n",
       "      <td>Armenia</td>\n",
       "      <td>AM</td>\n",
       "      <td>02</td>\n",
       "      <td>AM.02</td>\n",
       "      <td>Ararat</td>\n",
       "      <td>Ararat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   geonameid   name asciiname alternatenames  population  country  \\\n",
       "0     616435  Masis     Masis        Hrazdan       18911  Armenia   \n",
       "0     616435  Masis     Masis      Narimanlu       18911  Armenia   \n",
       "0     616435  Masis     Masis         Razdan       18911  Armenia   \n",
       "0     616435  Masis     Masis    Takhanshalu       18911  Armenia   \n",
       "0     616435  Masis     Masis    Tokhanshalu       18911  Armenia   \n",
       "\n",
       "  country_code admin1_code concat_code  region ascii_region  \n",
       "0           AM          02       AM.02  Ararat       Ararat  \n",
       "0           AM          02       AM.02  Ararat       Ararat  \n",
       "0           AM          02       AM.02  Ararat       Ararat  \n",
       "0           AM          02       AM.02  Ararat       Ararat  \n",
       "0           AM          02       AM.02  Ararat       Ararat  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22741, 11)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Названия городов без дубликатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Masis', 'Ararat', 'Artashat', ..., 'Bayburt', 'Akcakoca',\n",
       "       'Duezce'], dtype=object)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_list = corpus.asciiname.drop_duplicates().values\n",
    "names_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PCfPeqYvkpZ-"
   },
   "source": [
    "**Выберем предварительно обученную модель из библиотеки SentenceTransformer и загрузим ее**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at C:\\Users\\User/.cache\\torch\\sentence_transformers\\artefucktor_LaBSE_geonames_RU_RELOCATION\\ were not used when initializing BertModel: ['0.auto_model.encoder.layer.6.output.dense.weight', '0.auto_model.encoder.layer.7.attention.output.LayerNorm.bias', '0.auto_model.encoder.layer.10.attention.output.dense.bias', '0.auto_model.encoder.layer.3.intermediate.dense.weight', '0.auto_model.encoder.layer.8.intermediate.dense.bias', '0.auto_model.pooler.dense.weight', '0.auto_model.encoder.layer.8.output.LayerNorm.weight', '0.auto_model.encoder.layer.9.attention.output.LayerNorm.weight', '0.auto_model.encoder.layer.11.attention.self.value.bias', '0.auto_model.encoder.layer.4.attention.self.value.weight', '0.auto_model.encoder.layer.9.attention.output.LayerNorm.bias', '0.auto_model.encoder.layer.1.attention.output.LayerNorm.bias', '0.auto_model.encoder.layer.10.intermediate.dense.bias', '0.auto_model.encoder.layer.8.attention.self.key.weight', '0.auto_model.encoder.layer.9.output.LayerNorm.weight', '0.auto_model.encoder.layer.4.intermediate.dense.bias', '0.auto_model.encoder.layer.8.attention.self.value.bias', '0.auto_model.encoder.layer.8.attention.output.LayerNorm.bias', '0.auto_model.encoder.layer.1.attention.self.key.bias', '0.auto_model.encoder.layer.3.attention.self.value.bias', '0.auto_model.encoder.layer.1.attention.self.query.bias', '0.auto_model.encoder.layer.3.attention.self.query.weight', '0.auto_model.encoder.layer.6.attention.self.key.bias', '0.auto_model.encoder.layer.6.intermediate.dense.bias', '0.auto_model.embeddings.LayerNorm.bias', '0.auto_model.encoder.layer.8.attention.self.query.bias', '0.auto_model.encoder.layer.5.intermediate.dense.weight', '2.linear.weight', '0.auto_model.encoder.layer.3.attention.self.key.bias', '0.auto_model.encoder.layer.6.attention.self.key.weight', '0.auto_model.encoder.layer.0.attention.self.query.weight', '0.auto_model.encoder.layer.5.attention.output.LayerNorm.bias', '0.auto_model.encoder.layer.0.intermediate.dense.weight', '0.auto_model.encoder.layer.11.output.LayerNorm.weight', '0.auto_model.encoder.layer.11.attention.self.query.bias', '0.auto_model.encoder.layer.2.attention.output.LayerNorm.weight', '0.auto_model.encoder.layer.4.output.dense.weight', '0.auto_model.encoder.layer.7.intermediate.dense.weight', '0.auto_model.pooler.dense.bias', '0.auto_model.encoder.layer.7.attention.output.dense.weight', '0.auto_model.encoder.layer.3.attention.self.query.bias', '0.auto_model.encoder.layer.6.output.dense.bias', '0.auto_model.encoder.layer.0.attention.output.dense.bias', '0.auto_model.encoder.layer.10.attention.output.LayerNorm.weight', '0.auto_model.encoder.layer.10.output.LayerNorm.weight', '0.auto_model.encoder.layer.4.attention.self.value.bias', '0.auto_model.encoder.layer.8.output.LayerNorm.bias', '0.auto_model.encoder.layer.3.attention.output.LayerNorm.bias', '0.auto_model.encoder.layer.5.intermediate.dense.bias', '0.auto_model.encoder.layer.5.attention.self.query.weight', '0.auto_model.encoder.layer.6.attention.output.dense.bias', '0.auto_model.encoder.layer.7.attention.self.query.bias', '2.linear.bias', '0.auto_model.encoder.layer.10.attention.self.key.bias', '0.auto_model.encoder.layer.4.attention.self.query.weight', '0.auto_model.encoder.layer.7.attention.self.value.weight', '0.auto_model.embeddings.word_embeddings.weight', '0.auto_model.encoder.layer.8.attention.output.dense.weight', '0.auto_model.encoder.layer.9.attention.self.key.weight', '0.auto_model.encoder.layer.0.attention.self.key.weight', '0.auto_model.encoder.layer.7.intermediate.dense.bias', '0.auto_model.encoder.layer.9.attention.self.value.bias', '0.auto_model.encoder.layer.11.intermediate.dense.weight', '0.auto_model.encoder.layer.10.output.dense.bias', '0.auto_model.encoder.layer.11.attention.self.value.weight', '0.auto_model.encoder.layer.10.attention.output.LayerNorm.bias', '0.auto_model.encoder.layer.8.attention.output.LayerNorm.weight', '0.auto_model.encoder.layer.1.output.LayerNorm.weight', '0.auto_model.encoder.layer.1.output.LayerNorm.bias', '0.auto_model.encoder.layer.8.attention.self.key.bias', '0.auto_model.encoder.layer.4.output.LayerNorm.weight', '0.auto_model.encoder.layer.2.attention.self.key.weight', '0.auto_model.encoder.layer.3.attention.self.key.weight', '0.auto_model.encoder.layer.2.attention.output.dense.bias', '0.auto_model.encoder.layer.9.attention.self.query.weight', '0.auto_model.encoder.layer.10.intermediate.dense.weight', '0.auto_model.encoder.layer.6.intermediate.dense.weight', '0.auto_model.encoder.layer.5.output.dense.bias', '0.auto_model.encoder.layer.4.output.dense.bias', '0.auto_model.encoder.layer.9.attention.output.dense.bias', '0.auto_model.encoder.layer.11.output.LayerNorm.bias', '0.auto_model.encoder.layer.5.attention.output.dense.weight', '0.auto_model.encoder.layer.2.output.LayerNorm.bias', '0.auto_model.encoder.layer.2.attention.self.key.bias', '0.auto_model.encoder.layer.4.attention.self.query.bias', '0.auto_model.encoder.layer.2.intermediate.dense.bias', '0.auto_model.encoder.layer.9.intermediate.dense.bias', '0.auto_model.encoder.layer.8.output.dense.weight', '0.auto_model.encoder.layer.6.attention.self.value.bias', '0.auto_model.encoder.layer.11.attention.output.LayerNorm.weight', '0.auto_model.encoder.layer.3.attention.output.dense.bias', '0.auto_model.encoder.layer.3.output.LayerNorm.weight', '0.auto_model.encoder.layer.1.attention.self.key.weight', '0.auto_model.encoder.layer.7.output.dense.bias', '0.auto_model.encoder.layer.1.attention.output.dense.bias', '0.auto_model.encoder.layer.11.output.dense.bias', '0.auto_model.encoder.layer.7.attention.self.value.bias', '0.auto_model.embeddings.position_embeddings.weight', '0.auto_model.encoder.layer.2.intermediate.dense.weight', '0.auto_model.encoder.layer.8.intermediate.dense.weight', '0.auto_model.encoder.layer.2.attention.output.dense.weight', '0.auto_model.encoder.layer.0.attention.output.dense.weight', '0.auto_model.encoder.layer.2.attention.self.query.bias', '0.auto_model.encoder.layer.1.attention.self.query.weight', '0.auto_model.encoder.layer.8.attention.output.dense.bias', '0.auto_model.encoder.layer.7.output.dense.weight', '0.auto_model.encoder.layer.3.output.LayerNorm.bias', '0.auto_model.encoder.layer.5.attention.self.key.weight', '0.auto_model.encoder.layer.6.attention.output.dense.weight', '0.auto_model.encoder.layer.6.attention.output.LayerNorm.bias', '0.auto_model.encoder.layer.2.output.LayerNorm.weight', '0.auto_model.encoder.layer.5.attention.output.LayerNorm.weight', '0.auto_model.encoder.layer.6.output.LayerNorm.bias', '0.auto_model.encoder.layer.0.attention.self.key.bias', '0.auto_model.encoder.layer.6.attention.output.LayerNorm.weight', '0.auto_model.encoder.layer.10.attention.self.value.bias', '0.auto_model.encoder.layer.1.intermediate.dense.bias', '0.auto_model.encoder.layer.7.attention.self.key.weight', '0.auto_model.encoder.layer.0.output.dense.bias', '0.auto_model.encoder.layer.2.attention.self.value.bias', '0.auto_model.encoder.layer.11.attention.output.dense.bias', '0.auto_model.encoder.layer.3.attention.output.dense.weight', '0.auto_model.encoder.layer.1.attention.output.dense.weight', '0.auto_model.encoder.layer.8.attention.self.query.weight', '0.auto_model.encoder.layer.9.output.dense.bias', '0.auto_model.encoder.layer.10.attention.self.value.weight', '0.auto_model.encoder.layer.0.intermediate.dense.bias', '0.auto_model.encoder.layer.8.output.dense.bias', '0.auto_model.encoder.layer.10.output.dense.weight', '0.auto_model.encoder.layer.11.attention.self.query.weight', '0.auto_model.encoder.layer.7.output.LayerNorm.weight', '0.auto_model.encoder.layer.2.attention.self.value.weight', '0.auto_model.embeddings.LayerNorm.weight', '0.auto_model.encoder.layer.6.attention.self.value.weight', '0.auto_model.encoder.layer.11.attention.self.key.bias', '0.auto_model.encoder.layer.11.attention.output.LayerNorm.bias', '0.auto_model.encoder.layer.5.output.LayerNorm.bias', '0.auto_model.encoder.layer.5.attention.self.value.weight', '0.auto_model.encoder.layer.0.attention.self.value.weight', '0.auto_model.encoder.layer.10.attention.self.query.bias', '0.auto_model.encoder.layer.6.attention.self.query.bias', '0.auto_model.encoder.layer.6.attention.self.query.weight', '0.auto_model.encoder.layer.4.attention.output.LayerNorm.weight', '0.auto_model.encoder.layer.6.output.LayerNorm.weight', '0.auto_model.encoder.layer.5.attention.self.value.bias', '0.auto_model.encoder.layer.0.attention.output.LayerNorm.weight', '0.auto_model.encoder.layer.4.attention.self.key.bias', '0.auto_model.encoder.layer.3.output.dense.weight', '0.auto_model.encoder.layer.4.attention.output.dense.weight', '0.auto_model.encoder.layer.1.intermediate.dense.weight', '0.auto_model.encoder.layer.9.attention.self.value.weight', '0.auto_model.encoder.layer.10.attention.self.key.weight', '0.auto_model.encoder.layer.3.attention.output.LayerNorm.weight', '0.auto_model.embeddings.token_type_embeddings.weight', '0.auto_model.encoder.layer.10.attention.self.query.weight', '0.auto_model.encoder.layer.9.output.dense.weight', '0.auto_model.encoder.layer.7.attention.output.LayerNorm.weight', '0.auto_model.encoder.layer.9.attention.output.dense.weight', '0.auto_model.encoder.layer.1.attention.self.value.weight', '0.auto_model.encoder.layer.1.output.dense.weight', '0.auto_model.encoder.layer.11.intermediate.dense.bias', '0.auto_model.encoder.layer.4.attention.self.key.weight', '0.auto_model.encoder.layer.5.attention.self.query.bias', '0.auto_model.encoder.layer.0.output.LayerNorm.bias', '0.auto_model.encoder.layer.9.intermediate.dense.weight', '0.auto_model.encoder.layer.0.attention.self.query.bias', '0.auto_model.encoder.layer.7.output.LayerNorm.bias', '0.auto_model.encoder.layer.10.output.LayerNorm.bias', '0.auto_model.encoder.layer.0.attention.output.LayerNorm.bias', '0.auto_model.encoder.layer.9.attention.self.key.bias', '0.auto_model.encoder.layer.0.output.dense.weight', '0.auto_model.encoder.layer.7.attention.output.dense.bias', '0.auto_model.encoder.layer.9.output.LayerNorm.bias', '0.auto_model.encoder.layer.11.attention.output.dense.weight', '0.auto_model.encoder.layer.2.attention.output.LayerNorm.bias', '0.auto_model.encoder.layer.0.attention.self.value.bias', '0.auto_model.encoder.layer.1.attention.output.LayerNorm.weight', '0.auto_model.encoder.layer.2.output.dense.bias', '0.auto_model.encoder.layer.1.output.dense.bias', '0.auto_model.encoder.layer.11.attention.self.key.weight', '0.auto_model.encoder.layer.1.attention.self.value.bias', '0.auto_model.encoder.layer.4.attention.output.dense.bias', '0.auto_model.encoder.layer.4.output.LayerNorm.bias', '0.auto_model.encoder.layer.7.attention.self.key.bias', '0.auto_model.encoder.layer.4.attention.output.LayerNorm.bias', '0.auto_model.encoder.layer.0.output.LayerNorm.weight', '0.auto_model.encoder.layer.5.output.dense.weight', '0.auto_model.encoder.layer.10.attention.output.dense.weight', '0.auto_model.encoder.layer.7.attention.self.query.weight', '0.auto_model.encoder.layer.5.output.LayerNorm.weight', '0.auto_model.encoder.layer.11.output.dense.weight', '0.auto_model.encoder.layer.2.output.dense.weight', '0.auto_model.encoder.layer.3.attention.self.value.weight', '0.auto_model.encoder.layer.3.intermediate.dense.bias', '0.auto_model.encoder.layer.2.attention.self.query.weight', '0.auto_model.encoder.layer.5.attention.self.key.bias', '0.auto_model.encoder.layer.5.attention.output.dense.bias', '0.auto_model.encoder.layer.9.attention.self.query.bias', '0.auto_model.encoder.layer.4.intermediate.dense.weight', '0.auto_model.encoder.layer.8.attention.self.value.weight', '0.auto_model.encoder.layer.3.output.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at C:\\Users\\User/.cache\\torch\\sentence_transformers\\artefucktor_LaBSE_geonames_RU_RELOCATION\\ and are newly initialized: ['encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.weight', 'pooler.dense.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.3.attention.self.key.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.10.attention.self.key.weight', 'pooler.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.7.attention.self.key.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Загрузка предварительно обученной модели mBART и токенизатора\n",
    "model = SentenceTransformer('artefucktor/LaBSE_geonames_RU_RELOCATION')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как модель обучена на альтернативных именах, создадим эмбендинги для всех названий городов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.01756764  0.06759417  0.0062893  ... -0.01650135 -0.06111738\n",
      "   0.0183134 ]\n",
      " [-0.05108269  0.07602846  0.02132422 ... -0.01072385 -0.05783798\n",
      "  -0.00085994]\n",
      " [-0.05927843  0.07991929  0.02733636 ... -0.00619107 -0.05208034\n",
      "  -0.01652848]\n",
      " ...\n",
      " [-0.04823219  0.07744403  0.02462361 ... -0.0322054  -0.05414787\n",
      "  -0.00470967]\n",
      " [-0.04080104  0.07947501  0.00854814 ... -0.02015225 -0.05453103\n",
      "  -0.00165115]\n",
      " [-0.04958811  0.07369293  0.01528744 ... -0.02922699 -0.05832952\n",
      "   0.00272034]]\n"
     ]
    }
   ],
   "source": [
    "embeddings = model.encode(names_list)\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим экземпляр кастомного класса CountVec()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sem_mod = SemSearch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для проверки работы скрипта введем запрашиваемый город и количество ниболее близких названий городов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "city = 'влодекасток'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для подбора наиболее подходящих названий с geonames с помощью cosine-similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_sim = sem_mod.get_sim(city, names_list, \n",
    "            embeddings, model, corpus_rus, top=3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'geonameid': 174972,\n",
       "  'asciiname': \"Hats'avan\",\n",
       "  'region': 'Syunik',\n",
       "  'country': 'Armenia',\n",
       "  'score': 0.9614735841751099},\n",
       " {'geonameid': 1538636,\n",
       "  'asciiname': \"Novoural'sk\",\n",
       "  'region': 'Sverdlovsk Oblast',\n",
       "  'country': 'Russia',\n",
       "  'score': 0.9577018618583679},\n",
       " {'geonameid': 481350,\n",
       "  'asciiname': 'Trubchevsk',\n",
       "  'region': 'Bryansk Oblast',\n",
       "  'country': 'Russia',\n",
       "  'score': 0.9554844498634338}]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для подбора наиболее подходящих названий с geonames с помощью mahalanobis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_matrix = np.cov(embeddings, rowvar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_mah = sem_mod.get_mahalanobis(city, names_list, \n",
    "                embeddings, model, corpus_rus, cov_matrix, top=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'geonameid': 174972,\n",
       "  'asciiname': \"Hats'avan\",\n",
       "  'region': 'Syunik',\n",
       "  'country': 'Armenia',\n",
       "  'mahalanobis_distance': 0.006765640908900858},\n",
       " {'geonameid': 530849,\n",
       "  'asciiname': 'Maloyaroslavets',\n",
       "  'region': 'Kaluga Oblast',\n",
       "  'country': 'Russia',\n",
       "  'mahalanobis_distance': 0.007299732355036254},\n",
       " {'geonameid': 559654,\n",
       "  'asciiname': 'Gorodishche',\n",
       "  'region': 'Volgograd Oblast',\n",
       "  'country': 'Russia',\n",
       "  'mahalanobis_distance': 0.0073621988771283165}]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_mah"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Метод использования предобученной модели из tansformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выберем свою предварительно обученную модель из библиотеки transformer и загрузим ее**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка предварительно обученной модели mBART и токенизатора\n",
    "output_model_path = \"EldarKerimkhan/mbart-large-50-many-to-many-mmt.geonames_RU_RELOCATION\"\n",
    "model = MBartForConditionalGeneration.from_pretrained(output_model_path)\n",
    "tokenizer = MBart50TokenizerFast.from_pretrained(output_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_mod = GenSearch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для проверки работы скрипта введем запрашиваемый город и количество ниболее близких названий городов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "city = 'Истанбул'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для подбора наиболее подходящих названий с geonames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "result = gen_mod.gen_sim_mbart(city, tokenizer, model, corpus_rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'geonameid': 745044,\n",
       " 'asciiname': 'Istanbul',\n",
       " 'region': 'Istanbul',\n",
       " 'country': 'Turkey'}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yEcF31T1kpaB"
   },
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jZmi93inkpaB"
   },
   "source": [
    "В проекте была создана локальная база данных. В базу были загружены необходимые для выполнения задачи таблицы. А также запросом к базе данных выгружены данные, относящиеся к странам наиболее популярных для релокации. \n",
    "\n",
    "В данном файле были опробованы такие методы узнаваемости слова как:\n",
    "\n",
    " - Метод векторизации слова CountVectorizer();\n",
    " - Метод использования готовой предобученной модели из SentenceTransformers;\n",
    " - Метод использования своей предобученной модели из tansformers.\n",
    "\n",
    "Для каждого метода была проведена оценка качества в файле `geonames _test_file`. \n",
    "В целом, все методы дают результаты узнаваемости более 80%. \n",
    "\n",
    "Метод векторизации слова `CountVectorizer()` показал результаты хуже на 5%, чем другие два метода. \n",
    "Готовая модель из SentenceTransformers была предобученна на 5 эпохах.\n",
    "Своя модель была предобучена на 4 эпохах с использованием аугментации (случайных опечаток в слове Random Insertion)).\n",
    "\n",
    "Очень важно сделать *правильную предобработку исходных слов*, в том числе добавить дополнительные слова с другими аугментациями удаление символов, перестановка символов, семантические аугментации, расширение синонимами.\n",
    "\n",
    "В любом случае, все эти методы очень сильно зависят от столбца с *альтернативными названиями*. То есть данный словарь должен пополняться, если встречаются новые слова. (но пополняться осторожно, так как нужно различать, насколько данное слово подходит в качестве альтернативного названия). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DvNa0Un-kpaQ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 48,
    "start_time": "2023-07-26T14:57:15.827Z"
   },
   {
    "duration": 2856,
    "start_time": "2023-07-26T15:01:05.938Z"
   },
   {
    "duration": 137,
    "start_time": "2023-07-26T15:01:08.796Z"
   },
   {
    "duration": 15,
    "start_time": "2023-07-26T15:01:08.935Z"
   },
   {
    "duration": 446,
    "start_time": "2023-07-26T15:01:08.953Z"
   },
   {
    "duration": 104,
    "start_time": "2023-07-26T15:01:09.401Z"
   },
   {
    "duration": 18,
    "start_time": "2023-07-26T15:01:09.507Z"
   },
   {
    "duration": 43,
    "start_time": "2023-07-26T15:01:09.526Z"
   },
   {
    "duration": 114224,
    "start_time": "2023-07-26T15:01:09.570Z"
   },
   {
    "duration": 1901,
    "start_time": "2023-07-26T15:03:03.796Z"
   },
   {
    "duration": 28,
    "start_time": "2023-07-26T15:03:05.699Z"
   },
   {
    "duration": 1636,
    "start_time": "2023-07-26T15:03:05.730Z"
   }
  ],
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "166px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
